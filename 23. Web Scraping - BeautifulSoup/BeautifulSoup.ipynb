{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9813df54",
   "metadata": {},
   "source": [
    "# 23. Web Scraping - BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f089e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step to be followed:-\n",
    "\n",
    "#1 : load html [requests lib]\n",
    "#2 : parse HTML [beautifulsoup lib]\n",
    "#3 : locate and extract the desired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7869893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "480cbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<!DOCTYPE html>\\\n",
    "<html>\\\n",
    "<head>\\\n",
    "<title> Testing Web Page </title>\\\n",
    "</head>\\\n",
    "<body>\\\n",
    "<h1> Web Scraping </h1>\\\n",
    "<p id = \"first_para\">\\\n",
    "Let\\'s start learning \\\n",
    "<b>\\\n",
    "Web Scraping\\\n",
    "</b>\\\n",
    "</p>\\\n",
    "<p class = \"abc\" id = \"second_para\">\\\n",
    "You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>\\\n",
    "</p>\\\n",
    "<p class = \"abc\">\\\n",
    "<a href = \"https://codingninjas.in/\"> Coding Ninjas </a>\\\n",
    "</p>\\\n",
    "</body>\\\n",
    "</html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb48b1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bs(html,'html.parser')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664ae08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9713975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You can read more about BeautifulSoup from\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://codingninjas.in/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# beautify the data\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4ce1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "<head><title> Testing Web Page </title></head>\n",
      "<h1> Web Scraping </h1>\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n"
     ]
    }
   ],
   "source": [
    "# extract ->title\n",
    "# data.(tag_name)\n",
    "print(data.title)\n",
    "print(data.head)\n",
    "print(data.h1)\n",
    "print(data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bef46aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "title\n",
      " Testing Web Page \n"
     ]
    }
   ],
   "source": [
    "# extract content inside tag \n",
    "print(data.title) # complete desc of tag\n",
    "print(data.title.name) # tag name\n",
    "print(data.title.string) # only content of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd450809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'id': 'first_para'}\n"
     ]
    }
   ],
   "source": [
    "print(data.title.attrs) # show all attribute in particular tag present\n",
    "print(data.p.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "959c7e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_para\n",
      "first_para\n"
     ]
    }
   ],
   "source": [
    "# get value of id\n",
    "print(data.p.get('id')) # by using get()\n",
    "print(data.p['id']) # by using dict concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6530f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Web Page  Web Scraping Let's start learning Web ScrapingYou can read more about BeautifulSoup from  here  Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "print(data.get_text()) # only text , extrxct all text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b76a4a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# find() -> return first occurence of ele\n",
    "print(data.find('p'))\n",
    "print(data.find('pr')) # none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "911fd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>, <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>]\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>\n",
      "<p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>\n"
     ]
    }
   ],
   "source": [
    "# find_all() -- >all occurence of ele\n",
    "print(data.find_all('p'))\n",
    "\n",
    "# or\n",
    "li = data.find_all('p')\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54112030",
   "metadata": {},
   "source": [
    "### Navigate Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24246072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>,\n",
       " <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>,\n",
       " <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>,\n",
       " <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>,\n",
       " <a href=\"https://codingninjas.in/\"> Coding Ninjas </a>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching -> find() and find_all()\n",
    "data.find_all(['p','a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c231544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>,\n",
       " <head><title> Testing Web Page </title></head>,\n",
       " <title> Testing Web Page </title>,\n",
       " <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>,\n",
       " <h1> Web Scraping </h1>,\n",
       " <p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>,\n",
       " <b>Web Scraping</b>,\n",
       " <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>,\n",
       " <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>,\n",
       " <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>,\n",
       " <a href=\"https://codingninjas.in/\"> Coding Ninjas </a>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.find_all(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d35f2a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find id using id-name\n",
    "data.find_all(id = 'first_para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f968baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>, <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>]\n"
     ]
    }
   ],
   "source": [
    "print(data.find_all(class_ = 'abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe684c",
   "metadata": {},
   "source": [
    "#### Going down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86de79c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You can read more about BeautifulSoup from\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://codingninjas.in/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fb31180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<title> Testing Web Page </title>\n",
      "<title> Testing Web Page </title>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)\n",
    "print(data.head.title)\n",
    "print(data.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbeb9f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Web Page \n"
     ]
    }
   ],
   "source": [
    "print(data.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3a9c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      " Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p')\n",
    "for i in li:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f89e5e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning \", 'Web Scraping']\n",
      "['You can read more about BeautifulSoup from ', ' here ']\n",
      "[' Coding Ninjas ']\n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p') # find multiple children value\n",
    "for i in li:\n",
    "    print(list(i.strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab5a4d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning\", 'Web Scraping']\n",
      "['You can read more about BeautifulSoup from', 'here']\n",
      "['Coding Ninjas']\n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p') # find multiple children value and remove all extra spaces\n",
    "for i in li:\n",
    "    print(list(i.stripped_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24ebd9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<head><title> Testing Web Page </title></head>, <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# contents -> give list\n",
    "li = data.html.contents\n",
    "print(li)\n",
    "print(len(li)) # head and body so 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ad24e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>\n"
     ]
    }
   ],
   "source": [
    "li = data.html.children #children -> give ittrator\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ff038ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<title> Testing Web Page </title>\n",
      " Testing Web Page \n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>\n",
      "<h1> Web Scraping </h1>\n",
      " Web Scraping \n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "Let's start learning \n",
      "<b>Web Scraping</b>\n",
      "Web Scraping\n",
      "<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>\n",
      "You can read more about BeautifulSoup from \n",
      "<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>\n",
      " here \n",
      "<p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>\n",
      "<a href=\"https://codingninjas.in/\"> Coding Ninjas </a>\n",
      " Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "li = data.html.descendants\n",
    "for i in li:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "308bc317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# parent -> give direct html while patents give ittratoer\n",
    "print(data.html.parent) \n",
    "li = data.html.parents\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d6b01",
   "metadata": {},
   "source": [
    "## ASSIGNMENT SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f65aca",
   "metadata": {},
   "source": [
    "#### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6adb06f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><h1> About Us </h1><div class=\"first_div\"><p>Coding Ninjas Website</p><a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a><ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul></div><p id=\"template_p\">This is a template paragraph tag</p><a href=\"https://www.facebook.com/codingninjas/\">This is the link of our Facebook Page</a></body>\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "data = bs(html,\"html.parser\")\n",
    "#print(data.prettify())\n",
    "print(data.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54500ac5",
   "metadata": {},
   "source": [
    "#### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe7fd3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,'html.parser')\n",
    "#print(data.prettify())\n",
    "li = data.div.attrs\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067af5b",
   "metadata": {},
   "source": [
    "#### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fed561c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an unordered list. "
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "da = data.find_all('li')\n",
    "for i in da:\n",
    "    print(i.string,end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78965f1b",
   "metadata": {},
   "source": [
    "#### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6c7786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.codingninjas.in/\n",
      "https://www.facebook.com/codingninjas/\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "a = data.find_all('a')\n",
    "for i in a:\n",
    "    print(i.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84253055",
   "metadata": {},
   "source": [
    "#### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c5f84acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "\n",
    "a = [data.html.descendants]\n",
    "b = [data.html.children]\n",
    "print(len(a) - len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcaf52f",
   "metadata": {},
   "source": [
    "#### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c91fc428",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: htm.parser. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-de4b1b889c8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mli\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mul\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0;31m'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"htm.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mli\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mli\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software Programs Files\\Anaconda-Data\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mbuilder_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuilder_class\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                 raise FeatureNotFound(\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: htm.parser. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"htm.parser\")\n",
    "li = data.html.find_all('id')\n",
    "li"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
