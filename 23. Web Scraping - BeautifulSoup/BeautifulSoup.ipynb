{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8329194",
   "metadata": {},
   "source": [
    "# 23. Web Scraping - BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51576c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step to be followed:-\n",
    "\n",
    "#1 : load html [requests lib]\n",
    "#2 : parse HTML [beautifulsoup lib]\n",
    "#3 : locate and extract the desired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7bc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae0febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<!DOCTYPE html>\\\n",
    "<html>\\\n",
    "<head>\\\n",
    "<title> Testing Web Page </title>\\\n",
    "</head>\\\n",
    "<body>\\\n",
    "<h1> Web Scraping </h1>\\\n",
    "<p id = \"first_para\">\\\n",
    "Let\\'s start learning \\\n",
    "<b>\\\n",
    "Web Scraping\\\n",
    "</b>\\\n",
    "</p>\\\n",
    "<p class = \"abc\" id = \"second_para\">\\\n",
    "You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>\\\n",
    "</p>\\\n",
    "<p class = \"abc\">\\\n",
    "<a href = \"https://codingninjas.in/\"> Coding Ninjas </a>\\\n",
    "</p>\\\n",
    "</body>\\\n",
    "</html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cefdddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bs(html,'html.parser')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fbf897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1ee774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You can read more about BeautifulSoup from\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://codingninjas.in/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# beautify the data\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c91076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "<head><title> Testing Web Page </title></head>\n",
      "<h1> Web Scraping </h1>\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n"
     ]
    }
   ],
   "source": [
    "# extract ->title\n",
    "# data.(tag_name)\n",
    "print(data.title)\n",
    "print(data.head)\n",
    "print(data.h1)\n",
    "print(data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40cc58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "title\n",
      " Testing Web Page \n"
     ]
    }
   ],
   "source": [
    "# extract content inside tag \n",
    "print(data.title) # complete desc of tag\n",
    "print(data.title.name) # tag name\n",
    "print(data.title.string) # only content of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abf16715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'id': 'first_para'}\n"
     ]
    }
   ],
   "source": [
    "print(data.title.attrs) # show all attribute in particular tag present\n",
    "print(data.p.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6560f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_para\n",
      "first_para\n"
     ]
    }
   ],
   "source": [
    "# get value of id\n",
    "print(data.p.get('id')) # by using get()\n",
    "print(data.p['id']) # by using dict concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83de2312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Web Page  Web Scraping Let's start learning Web ScrapingYou can read more about BeautifulSoup from  here  Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "print(data.get_text()) # only text , extrxct all text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c5580c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# find() -> return first occurence of ele\n",
    "print(data.find('p'))\n",
    "print(data.find('pr')) # none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5c9174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>, <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>]\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>\n",
      "<p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>\n"
     ]
    }
   ],
   "source": [
    "# find_all() -- >all occurence of ele\n",
    "print(data.find_all('p'))\n",
    "\n",
    "# or\n",
    "li = data.find_all('p')\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e145d",
   "metadata": {},
   "source": [
    "## ASSIGNMENT SOLUTION "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
