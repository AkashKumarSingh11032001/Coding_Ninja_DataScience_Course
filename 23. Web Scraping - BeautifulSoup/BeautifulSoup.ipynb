{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb27268e",
   "metadata": {},
   "source": [
    "# 23. Web Scraping - BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf60aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step to be followed:-\n",
    "\n",
    "#1 : load html [requests lib]\n",
    "#2 : parse HTML [beautifulsoup lib]\n",
    "#3 : locate and extract the desired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563c1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "957b2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<!DOCTYPE html>\\\n",
    "<html>\\\n",
    "<head>\\\n",
    "<title> Testing Web Page </title>\\\n",
    "</head>\\\n",
    "<body>\\\n",
    "<h1> Web Scraping </h1>\\\n",
    "<p id = \"first_para\">\\\n",
    "Let\\'s start learning \\\n",
    "<b>\\\n",
    "Web Scraping\\\n",
    "</b>\\\n",
    "</p>\\\n",
    "<p class = \"abc\" id = \"second_para\">\\\n",
    "You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>\\\n",
    "</p>\\\n",
    "<p class = \"abc\">\\\n",
    "<a href = \"https://codingninjas.in/\"> Coding Ninjas </a>\\\n",
    "</p>\\\n",
    "</body>\\\n",
    "</html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec1fca6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bs(html,'html.parser')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ef1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92ef86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You can read more about BeautifulSoup from\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://codingninjas.in/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# beautify the data\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f84f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "<head><title> Testing Web Page </title></head>\n",
      "<h1> Web Scraping </h1>\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n"
     ]
    }
   ],
   "source": [
    "# extract ->title\n",
    "# data.(tag_name)\n",
    "print(data.title)\n",
    "print(data.head)\n",
    "print(data.h1)\n",
    "print(data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26b34b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title> Testing Web Page </title>\n",
      "title\n",
      " Testing Web Page \n"
     ]
    }
   ],
   "source": [
    "# extract content inside tag \n",
    "print(data.title) # complete desc of tag\n",
    "print(data.title.name) # tag name\n",
    "print(data.title.string) # only content of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6646aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'id': 'first_para'}\n"
     ]
    }
   ],
   "source": [
    "print(data.title.attrs) # show all attribute in particular tag present\n",
    "print(data.p.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e6a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_para\n",
      "first_para\n"
     ]
    }
   ],
   "source": [
    "# get value of id\n",
    "print(data.p.get('id')) # by using get()\n",
    "print(data.p['id']) # by using dict concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b5c0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Web Page  Web Scraping Let's start learning Web ScrapingYou can read more about BeautifulSoup from  here  Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "print(data.get_text()) # only text , extrxct all text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aae0cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# find() -> return first occurence of ele\n",
    "print(data.find('p'))\n",
    "print(data.find('pr')) # none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "467433d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>, <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>]\n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>\n",
      "<p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>\n"
     ]
    }
   ],
   "source": [
    "# find_all() -- >all occurence of ele\n",
    "print(data.find_all('p'))\n",
    "\n",
    "# or\n",
    "li = data.find_all('p')\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d0ae9",
   "metadata": {},
   "source": [
    "### Navigate Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ac4ff52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>,\n",
       " <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>,\n",
       " <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>,\n",
       " <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>,\n",
       " <a href=\"https://codingninjas.in/\"> Coding Ninjas </a>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching -> find() and find_all()\n",
    "data.find_all(['p','a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8c07a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>,\n",
       " <head><title> Testing Web Page </title></head>,\n",
       " <title> Testing Web Page </title>,\n",
       " <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>,\n",
       " <h1> Web Scraping </h1>,\n",
       " <p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>,\n",
       " <b>Web Scraping</b>,\n",
       " <p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>,\n",
       " <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>,\n",
       " <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>,\n",
       " <a href=\"https://codingninjas.in/\"> Coding Ninjas </a>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.find_all(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c193e709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find id using id-name\n",
    "data.find_all(id = 'first_para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11351290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>, <p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>]\n"
     ]
    }
   ],
   "source": [
    "print(data.find_all(class_ = 'abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5effe",
   "metadata": {},
   "source": [
    "#### Going down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a349a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You can read more about BeautifulSoup from\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://codingninjas.in/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9ebe3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<title> Testing Web Page </title>\n",
      "<title> Testing Web Page </title>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)\n",
    "print(data.head.title)\n",
    "print(data.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85b1458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing Web Page \n"
     ]
    }
   ],
   "source": [
    "print(data.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a76a85ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      " Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p')\n",
    "for i in li:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2e036c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning \", 'Web Scraping']\n",
      "['You can read more about BeautifulSoup from ', ' here ']\n",
      "[' Coding Ninjas ']\n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p') # find multiple children value\n",
    "for i in li:\n",
    "    print(list(i.strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e294d90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning\", 'Web Scraping']\n",
      "['You can read more about BeautifulSoup from', 'here']\n",
      "['Coding Ninjas']\n"
     ]
    }
   ],
   "source": [
    "li = data.find_all('p') # find multiple children value and remove all extra spaces\n",
    "for i in li:\n",
    "    print(list(i.stripped_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80d12d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<head><title> Testing Web Page </title></head>, <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# contents -> give list\n",
    "li = data.html.contents\n",
    "print(li)\n",
    "print(len(li)) # head and body so 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7df982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>\n"
     ]
    }
   ],
   "source": [
    "li = data.html.children #children -> give ittrator\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ad47957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title> Testing Web Page </title></head>\n",
      "<title> Testing Web Page </title>\n",
      " Testing Web Page \n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body>\n",
      "<h1> Web Scraping </h1>\n",
      " Web Scraping \n",
      "<p id=\"first_para\">Let's start learning <b>Web Scraping</b></p>\n",
      "Let's start learning \n",
      "<b>Web Scraping</b>\n",
      "Web Scraping\n",
      "<p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p>\n",
      "You can read more about BeautifulSoup from \n",
      "<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a>\n",
      " here \n",
      "<p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p>\n",
      "<a href=\"https://codingninjas.in/\"> Coding Ninjas </a>\n",
      " Coding Ninjas \n"
     ]
    }
   ],
   "source": [
    "li = data.html.descendants\n",
    "for i in li:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "96abf715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title> Testing Web Page </title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning <b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You can read more about BeautifulSoup from <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> here </a></p><p class=\"abc\"><a href=\"https://codingninjas.in/\"> Coding Ninjas </a></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# parent -> give direct html while patents give ittratoer\n",
    "print(data.html.parent) \n",
    "li = data.html.parents\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c96eb",
   "metadata": {},
   "source": [
    "### First Web-page   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1e05e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HEADER>\n",
      "<TITLE>The World Wide Web project</TITLE>\n",
      "<NEXTID N=\"55\">\n",
      "</HEADER>\n",
      "<BODY>\n",
      "<H1>World Wide Web</H1>The WorldWideWeb (W3) is a wide-area<A\n",
      "NAME=0 HREF=\"WhatIs.html\">\n",
      "hypermedia</A> information retrieval\n",
      "initiative aiming to give universal\n",
      "access to a large universe of documents.<P>\n",
      "Everything there is online about\n",
      "W3 is linked directly or indirectly\n",
      "to this document, including an <A\n",
      "NAME=24 HREF=\"Summary.html\">executive\n",
      "summary</A> of the project, <A\n",
      "NAME=29 HREF=\"Administration/Mailing/Overview.html\">Mailing lists</A>\n",
      ", <A\n",
      "NAME=30 HREF=\"Policy.html\">Policy</A> , November's  <A\n",
      "NAME=34 HREF=\"News/9211.html\">W3  news</A> ,\n",
      "<A\n",
      "NAME=41 HREF=\"FAQ/List.html\">Frequently Asked Questions</A> .\n",
      "<DL>\n",
      "<DT><A\n",
      "NAME=44 HREF=\"../DataSources/Top.html\">What's out there?</A>\n",
      "<DD> Pointers to the\n",
      "world's online information,<A\n",
      "NAME=45 HREF=\"../DataSources/bySubject/Overview.html\"> subjects</A>\n",
      ", <A\n",
      "NAME=z54 HREF=\"../DataSources/WWW/Servers.html\">W3 servers</A>, etc.\n",
      "<DT><A\n",
      "NAME=46 HREF=\"Help.html\">Help</A>\n",
      "<DD> on the browser you are using\n",
      "<DT><A\n",
      "NAME=13 HREF=\"Status.html\">Software Products</A>\n",
      "<DD> A list of W3 project\n",
      "components and their current state.\n",
      "(e.g. <A\n",
      "NAME=27 HREF=\"LineMode/Browser.html\">Line Mode</A> ,X11 <A\n",
      "NAME=35 HREF=\"Status.html#35\">Viola</A> ,  <A\n",
      "NAME=26 HREF=\"NeXT/WorldWideWeb.html\">NeXTStep</A>\n",
      ", <A\n",
      "NAME=25 HREF=\"Daemon/Overview.html\">Servers</A> , <A\n",
      "NAME=51 HREF=\"Tools/Overview.html\">Tools</A> ,<A\n",
      "NAME=53 HREF=\"MailRobot/Overview.html\"> Mail robot</A> ,<A\n",
      "NAME=52 HREF=\"Status.html#57\">\n",
      "Library</A> )\n",
      "<DT><A\n",
      "NAME=47 HREF=\"Technical.html\">Technical</A>\n",
      "<DD> Details of protocols, formats,\n",
      "program internals etc\n",
      "<DT><A\n",
      "NAME=40 HREF=\"Bibliography.html\">Bibliography</A>\n",
      "<DD> Paper documentation\n",
      "on  W3 and references.\n",
      "<DT><A\n",
      "NAME=14 HREF=\"People.html\">People</A>\n",
      "<DD> A list of some people involved\n",
      "in the project.\n",
      "<DT><A\n",
      "NAME=15 HREF=\"History.html\">History</A>\n",
      "<DD> A summary of the history\n",
      "of the project.\n",
      "<DT><A\n",
      "NAME=37 HREF=\"Helping.html\">How can I help</A> ?\n",
      "<DD> If you would like\n",
      "to support the web..\n",
      "<DT><A\n",
      "NAME=48 HREF=\"../README.html\">Getting code</A>\n",
      "<DD> Getting the code by<A\n",
      "NAME=49 HREF=\"LineMode/Defaults/Distribution.html\">\n",
      "anonymous FTP</A> , etc.</A>\n",
      "</DL>\n",
      "</BODY>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://info.cern.ch/hypertext/WWW/TheProject.html')\n",
    "#print(res)\n",
    "#print(res.headers)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6039e9",
   "metadata": {},
   "source": [
    "## ASSIGNMENT SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd35d6f",
   "metadata": {},
   "source": [
    "#### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cce5da6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><h1> About Us </h1><div class=\"first_div\"><p>Coding Ninjas Website</p><a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a><ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul></div><p id=\"template_p\">This is a template paragraph tag</p><a href=\"https://www.facebook.com/codingninjas/\">This is the link of our Facebook Page</a></body>\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "data = bs(html,\"html.parser\")\n",
    "#print(data.prettify())\n",
    "print(data.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31983fee",
   "metadata": {},
   "source": [
    "#### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6e3ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,'html.parser')\n",
    "#print(data.prettify())\n",
    "li = data.div.attrs\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24032ffe",
   "metadata": {},
   "source": [
    "#### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e23eef2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an unordered list. "
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "da = data.find_all('li')\n",
    "for i in da:\n",
    "    print(i.string,end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0eb9ef",
   "metadata": {},
   "source": [
    "#### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1833d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.codingninjas.in/\n",
      "https://www.facebook.com/codingninjas/\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "a = data.find_all('a')\n",
    "for i in a:\n",
    "    print(i.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539829bd",
   "metadata": {},
   "source": [
    "#### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "569506ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "\n",
    "a = [data.html.descendants]\n",
    "b = [data.html.children]\n",
    "print(len(a) - len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2848d",
   "metadata": {},
   "source": [
    "#### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ce3eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "h1\n",
      "a\n",
      "ul\n",
      "li\n",
      "p\n",
      "b\n",
      "p\n",
      "li\n",
      "li\n",
      "ol\n",
      "li\n",
      "li\n",
      "li\n",
      "li\n",
      "li\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "li = data.find_all(id)\n",
    "for i in li:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7fb3e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li>\n",
      "<li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li>\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "page = data.find(\"li\",{\"id\":\"li2\"})\n",
    "\n",
    "temp = list(page.next_siblings)\n",
    "for i in temp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b4edd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>Navigate Parse Tree</title></head>\n",
      "<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "page = data.find(\"title\")\n",
    "temp = list(page.parents)\n",
    "for i in temp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7bb3bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicking on this takes you to the documentation of BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "data = bs(html,\"html.parser\")\n",
    "page = data.find_all('a')[1]\n",
    "print(page.next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34817790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
